{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item Demand Forecasting\n",
    "This notebook details some basic code to get a simple time series forecasting algorithms up and running for several item demand profiles. The focus here is not an optimised algorithm, but to create a simple base model from which we can explore the concepts of machine learning engineering in the rest of the book.\n",
    "\n",
    "## The Problem\n",
    "The problem outlined in the book is deceptively complex, so here we will re-iterate some of the details\n",
    "\n",
    "1. The aim is to create a suite of forecasting models for many items in many regions\n",
    "2. The user will interface with the models via a basic frontend\n",
    "3. The user should have the ability to:\n",
    "    a. Select the forecasts they want to see\n",
    "    b. Ask for a retrain of the selected forecasting models (and then have the forecasts updated)\n",
    "    c. [BONUS] Add conditional variables to perform scenario analysis\n",
    "    \n",
    "From a machine learning point of view this can be supplied via:\n",
    "\n",
    "1. A batch training of N baseline models (N = combinations of region and product)\n",
    "2. Storing of the models in MLFlow\n",
    "3. The app, when requested for specific models, can retrieve the models from MLFlow and cache them for the session\n",
    "4. The app, when requested for specific forecasts, can performt the forecasts on the cached models\n",
    "5. The app, when requested for retrains, can send a request to trigger a training run of the selected models in the original batch system.\n",
    "6. The training system, when requested for retrains, can compare performance against current models in MLFlow and decised to promote to 'production'\n",
    "7. The app will have to detect that there is a new production model in MLFlow and replace current model (to work this out)\n",
    "\n",
    "## This Notebook\n",
    "This notebook will create some baseline experiments to show that forecasting can be done at the region and item level, but will not concern itself with scaling to all regions and items nor with the deployment architecture and methodology (to be discussed later in the book)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "from fbprophet import Prophet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/rossman/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Date', 'Store', 'Sales']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['StateHoliday','SchoolHoliday']].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train basic forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns= {'Date': 'ds', 'Sales': 'y'}, inplace=True)\n",
    "df_store1 = df[\n",
    "    (df['Store']==4) &\\\n",
    "    (df['Open']==1)\n",
    "].reset_index(drop=True)\n",
    "df_store1 = df_store1.sort_values('ds', ascending=True)\n",
    "df_store1.plot(x='ds', y='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store1['DayOfWeek'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_store1 = df_store1[['ds', 'y']].set_index('ds').resample('1W').mean().reset_index()\n",
    "# df_store1.plot(x='ds', y='y')\n",
    "# #df_store1[['ds', 'y']].set_index('ds').resample('1W').mean().reset_index().plot(x='ds', y='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_store1[\n",
    "#     (df_store1['ds']>'2013-02') & (df_store1['ds']<'2013-09')\n",
    "# ].sort_values('ds', ascending=False).plot(x='ds', y='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_store1 = df_store1[\n",
    "#     (df_store1['ds']>'2013-02') & (df_store1['ds']<'2013-09')\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store1.sort_values('ds', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonality = {\n",
    "    'yearly': True,\n",
    "    'weekly': True,\n",
    "    'daily': False\n",
    "}\n",
    "\n",
    "def train_predict(df, train_index, seasonality=seasonality):\n",
    "    # grab split data\n",
    "    df_train = df.copy().iloc[0:train_index]\n",
    "    df_test = df.copy().iloc[train_index:]\n",
    "    \n",
    "    #create Prophet model\n",
    "    model=Prophet(\n",
    "        yearly_seasonality=seasonality['yearly'],\n",
    "        weekly_seasonality=seasonality['weekly'],\n",
    "        daily_seasonality=seasonality['daily'],\n",
    "        interval_width = 0.95\n",
    "    )\n",
    "\n",
    "    # train and predict\n",
    "    model.fit(df_train)\n",
    "    predicted = model.predict(df_test)\n",
    "    return predicted, df_train, df_test\n",
    "    \n",
    "    \n",
    "    \n",
    "# def time_split_train_test(df, time_series_splits, seasonality=seasonality):\n",
    "#     # for outputting\n",
    "#     df_results = pd.DataFrame()\n",
    "    \n",
    "#     for i,(train_i,test_i) in enumerate(time_series_splits.split(df)):\n",
    "        \n",
    "#         # grab split data\n",
    "#         df_train = df.copy().iloc[train_i,:]\n",
    "#         df_test = df.copy().iloc[test_i,:]\n",
    "\n",
    "#         # create Prophet model\n",
    "#         model=Prophet(\n",
    "#             yearly_seasonality=seasonality['yearly'],\n",
    "#             weekly_seasonality=seasonality['weekly'],\n",
    "#             daily_seasonality=seasonality['daily']\n",
    "#         )\n",
    "\n",
    "#         # train and predict\n",
    "#         model.fit(df_train)\n",
    "#         predicted = model.predict(df_test)\n",
    "\n",
    "#         # combine pred and training df's for plotting\n",
    "#         df_pred = predicted.loc[:,[\"ds\",\"yhat\"]]\n",
    "        \n",
    "#         df_pred[\"y\"] = df_test['y'].tolist()\n",
    "        \n",
    "#         # Train or Test?\n",
    "#         df_train[\"train\"]=True\n",
    "#         df_pred[\"train\"]=False\n",
    "        \n",
    "#         df_sub = df_train.append(df_pred).reset_index(drop=True)\n",
    "#         df_sub[\"split\"]=i\n",
    "#         df_sub[\"rmse\"]=(np.mean((df_sub.yhat-df_sub.y)**2))**.5 #calculating rmse for the split\n",
    "        \n",
    "#         df_results = df_results.append(df_sub).reset_index(drop=True)\n",
    "#     return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = int(0.8*df_store1.shape[0])\n",
    "predicted, df_train, df_test = train_predict(\n",
    "    df = df_store1,\n",
    "    train_index = train_index,\n",
    "    seasonality=seasonality\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "df_test.plot(x='ds', y='y', ax=ax, label='Truth', linewidth=1, markersize=5, color='tab:blue',alpha=0.9, marker='o')\n",
    "predicted.plot(x='ds', y='yhat', ax=ax, label='Prediction', linewidth=2, markersize=5, color='k')\n",
    "ax.fill_between(x=predicted['ds'], y1=predicted['yhat_upper'], y2=predicted['yhat_lower'], alpha=0.1, color='k')\n",
    "df_train.iloc[train_index-100:].plot(x='ds', y='y', ax=ax, color='tab:blue', label='_nolegend_', alpha=0.5, marker='o')\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = int(0.8*df_store1.shape[0])\n",
    "# grab split data\n",
    "df_train = df_store1.copy().iloc[0:train_index]\n",
    "df_test = df_store1.copy().iloc[train_index:]\n",
    "\n",
    "#create Prophet model\n",
    "model=Prophet(\n",
    "    yearly_seasonality=seasonality['yearly'],\n",
    "    weekly_seasonality=seasonality['weekly'],\n",
    "    daily_seasonality=seasonality['daily']\n",
    ")\n",
    "\n",
    "# train and predict\n",
    "model.fit(df_train)\n",
    "predicted = model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store1.iloc[0:train_index]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mleng-spark3]",
   "language": "python",
   "name": "conda-env-mleng-spark3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
